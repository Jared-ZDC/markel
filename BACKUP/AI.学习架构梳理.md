---
title: AI 学习架构梳理
date: 2024-09-12 03:41:42
tags: 总结思考
categories: 总结思考
toc: true
---
# 摘要

最近要把AI 整体自底向上的梳理一遍，同时把自己的知识面好好扩充一下，因此需要整体的看看，主要有哪些东西，并且这些东西，应该从哪些地方去补充知识；

坦白说，这部分跟我自己以往的工作经历差别有点大，从通用服务器芯片的全栈，要转移到AI专用芯片的全栈，这个里面涵盖的知识面可能相对通用服务器要求的更高，所以这里可能近一年需要花比较多的功夫；

---

 **雄关漫道真如铁，而今迈步从头越**

---



<!-- more -->



# 详细对比

几个关键点的主要差别：

* **芯片** ： 需要了解当前业界的主要的AI芯片的架构分析以及总结，比如AMD、Nvidia、mobileeye、华为昇腾、特斯拉；
* **底软** ： 底软在服务器这边主要是底层驱动以及操作系统，这边由于是专用芯片，可能涉及到底层BSP的差异以及操作系统的差别，比如linux\qnx\lanting\rtos等
* **编译器** ：在服务器这边，其实大部分都是通用的gcc编译器，但是在AI这边编译器都是各不一样，但是大部分都是基于LLVM做后端+编译IR前端，这部分难度比较高，需要先大致了解，并且实操一下，才能有体感；
* **编程框架** ： 在服务器这边都是基于linux的编程框架，所以比较通用，不需要专门了解，但是在ＡＩ专用芯片上，针对编程框架，涉及到不同芯片的ISA、不同芯片的框架，比如pytorch、tersorflow、天工开物、mindspore等
* **算法** :  AI专用芯片的算法需要编程框架以及编译器支持，甚至芯片要特制化，所以理解算法的基础上，才能理解后端的设计原因；
![AI系统架构图](https://github.com/user-attachments/assets/405f5c3a-1da5-4a42-917b-dd7259539a49)

![AI系统](https://github.com/user-attachments/assets/fe5b2204-1adb-4483-9395-21a3d1d75c2c)

## 行动项

* 梳理业界当前的AI\GPU 芯片的架构分析总结 --- 计划在9-10月底之前完成
* 在实验室中，搭建天工开物的实验室环境 --- 计划在9月底之前完成
* 《李宏毅的机器学习》课程 --- 计划9-10月底之前完成
* 《pytorch/tersorflow编程框架》 --- 计划11-12月底之前完成

暂时先这么定，过程中，随时调整目标以及计划；